---
title: "Analysis of funder selectivity: individual level data"
format: 
  html:
    code-fold: true
  #pdf: default
execute:
  keep-md: true
---

Research questions:

-   Are always the same teams receiving funding?
-   Are those that are being funded also those that share data?
-   Are those that share data / receive funding more or less central in the
    network?

```{r, echo=FALSE, message=FALSE}
library(sparklyr)
library(ggplot2)
library(patchwork)
library(dplyr)
library(arrow)
library(here)
library(tidygraph)

extrafont::loadfonts()
theme_set(theme_bw(base_family = "Hind"))

source(here("R/functions.R"))

Sys.setenv(SPARK_HOME = "/home/tklebel/spark-3.4.0-bin-hadoop3/")
Sys.setenv(HADOOP_HOME = "/home/hadoop/hadoop-3.3.1")
Sys.setenv(HADOOP_CONF_DIR = "/home/hadoop/hadoop-3.3.1/etc/hadoop")
Sys.setenv(YARN_HOME = "/home/hadoop/hadoop-3.3.1")
Sys.setenv(YARN_CONF_DIR = "/home/hadoop/hadoop-3.3.1/etc/hadoop")
Sys.setenv(JAVA_HOME="/usr/lib/jvm/java-1.11.0-openjdk-amd64")

config <- spark_config()
config$spark.executor.cores <- 5
config$spark.executor.instances <- 38
config$spark.executor.memory <- "20G"
config$spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version <- 2

sc <- spark_connect(master = "yarn", config = config,
                    app_name = "funding_selectivity_individual_data")

fragmented <- spark_read_parquet(
  sc, "fragmented",
  path = "/tklebel/data_sharing_abm/vary_incentives_individuals_fragmented_re_arranged.parquet",
  memory = TRUE
)

no_network <- spark_read_parquet(
  sc, "no_network",
  path = "/tklebel/data_sharing_abm/vary_incentives_individuals_no_network_re_arranged.parquet",
  memory = TRUE
)

```

# Are always the same teams receiving funding?

```{r}
# we did not store whether a given team was funded, and it is quite 
# time-consuming to re-run everything. We can compute this (with quite some
# effort) by checking if their total funding increased or not.

# check funding progress
funding_status <- fragmented %>% 
  filter(sharingincentive == .4,
         # we can restrict this to steps above 2000, since we are interested in
         # the equilibrium state here
         step >= 2000)
```

```{r, eval=FALSE}
# lagged model for funding

regression_results <- funding_status %>% 
  # it also fails currently, no idea why
  ml_logistic_regression(funded ~ initial_resources + funded_lag) 
```

```{r, eval=FALSE}
print(regression_results)
```

There seems to be a massive effect of the lagged funding status, if we take a
global look at all funding incentive settings.

```{r}
correlations <- funding_status %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(cor_funding = cor(as.numeric(funded), as.numeric(funded_lag)),
            cor_init_resources = cor(as.numeric(funded), as.numeric(initial_resources))) %>% 
  collect()
```

```{r}
correlations %>% 
  arrange(maxinitialutility, fundedshare) %>% 
  knitr::kable()
```

```{r}
correlations %>% 
  ggplot(aes(fundedshare, cor_funding, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

The correlation between current and previous funding status is very high - there
seems to be almost complete path dependency, once the simulation has entered the
equilibrium state.

```{r}
correlations %>% 
  ggplot(aes(fundedshare, cor_init_resources, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

Interestingly, the correlation with initial resources is much lower. For uniform
initial utility, it is relatively low across all funding selectivity settings.

For low initial utility, this is not true, and there is actually a negative
correlation. This lends credence to our initial hypothesis: teams with initially
higher resources (presumably, to be confirmed below) share less data, and thus
are less successful under the incentive regime.

## No network

```{r}
funding_status_no_network <- no_network %>% 
  filter(sharingincentive == .4,
         # we can restrict this to steps above 2000, since we are interested in
         # the equilibrium state here
         step >= 2000)
```

```{r, eval=FALSE}
regression_results <- funding_status_no_network %>% 
  # it also fails currently, no idea why
  ml_logistic_regression(funded ~ initial_resources + funded_lag) 
```

```{r, eval=FALSE}
print(regression_results)
```

With the baseline without a network, there is equally a strong influence of path
dependency. Initial resources have a slightly stronger role than in the case of
the fragmented network.

```{r}
correlations_no_network <- funding_status_no_network %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(cor_funding = cor(as.numeric(funded), as.numeric(funded_lag)),
            cor_init_resources = cor(as.numeric(funded), as.numeric(initial_resources))) %>% 
  collect()
```

```{r}
correlations_no_network %>% 
  arrange(maxinitialutility, fundedshare) %>% 
  knitr::kable()
```

```{r}
correlations_no_network %>% 
  ggplot(aes(fundedshare, cor_funding, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

Correlations for funding lag are similarly very high. However, behaviour is
different between max-initial-utility, comparing to the case of the fragmented
network. Here, correlations are higher for maxinitalutility = 4, but lower
otherwise.

```{r}
correlations_no_network %>% 
  ggplot(aes(fundedshare, cor_init_resources, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

These correlations are stronger, i.e., more positive, as indicated by the
regression: without networks, initial resources play a stronger role in who gets
funded, especially if funding is very selective.

To our initial question for the difference between utility settings: path
dependency is much lower for low initial utility. There is even a slight
negative correlation between initial resources and funding: initially
lower-resourced teams are funded more than those with higher initial resources,
simply because they start sharing data. If utility is uniform, initial resources
play a stronger role - there is more path dependency.

# Are those that are being funded also those that share data?

```{r}
funding_vs_sharing <- funding_status %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(cor_funding_sharing = cor(as.numeric(funded), as.numeric(shared_data)),
            cor_sharing_lag = cor(as.numeric(shared_data), as.numeric(shared_data_lag))) %>% 
  collect()
```

```{r}
funding_vs_sharing %>% 
  ggplot(aes(fundedshare, cor_funding_sharing, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

Generally speaking, those that are being funded are also those that share data,
in this instance. The correlation is stronger for less selective regimes. What
does this indicate? Maybe the broader reach of the funding agency, if many teams
are being funded? But wouldn't it be the case that if funding is more selective,
only those that are funded also share data, because it is too costly otherwise?
But maybe it is the opposite: if funding is very selective, not many teams can
afford to share data, and thus not many do. If funding is less selective, more
teams share data, and thus, generally, those being funded are also more often
those which share data. Does this make sense?

## No network

```{r}
funding_vs_sharing %>% 
  ggplot(aes(fundedshare, cor_sharing_lag, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

The correlation between sharing, and the shared lag (whether teams keep sharing
data) is also quite high, and the graph looks very similar to the one right
above. This implies that there is path dependency around sharing, where teams
share data and receive funding, while others do neither.

```{r}
funding_vs_sharing_no_network <- funding_status_no_network %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(cor_funding_sharing = cor(as.numeric(funded), as.numeric(shared_data)),
            cor_sharing_lag = cor(as.numeric(shared_data), as.numeric(shared_data_lag))) %>% 
  collect()
```

```{r}
funding_vs_sharing_no_network %>% 
  ggplot(aes(fundedshare, cor_funding_sharing, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

```{r}
funding_vs_sharing_no_network %>% 
  ggplot(aes(fundedshare, cor_sharing_lag, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

Again, we see that the correlation between funding and sharing seems to be
largely driven by previous sharing - the correlations between sharing and
sharing lag are essentially the same, just slightly lower.

We can thus conclude, that generally speaking, those who share data are also
those who receive funding. However, in the case of no networks, this correlation
is weaker, and especially weaker in case of low initial utility.

# Are those that share data / receive funding more or less central in the network?

HIGHLY INTERESTING OBSERVATION: in the fragmented network, it is mostly those
teams which are not well-connected that keep sharing data (in line with the
general finding that no network leads to more sharing than having a network.
Those that are closer to having no network (low degree) are thus more likely to
share). Is it then also those that receive more funding? Need to compare with
centrality measures.

This might be the reason, why the means that we show are much smoother for the
fragmented network, compared to the clustered, and especially the random
network: in the fragmented network, the types of nodes sharing data are quite
similar across runs, because there is a strong difference in degree between the
nodes. In the clustered, and more so in the random network, there are not so big
differences in degree, and thus there is more variability in who shares.

```{r}
# get network data
fragmented_network <- igraph::read_graph(here("network_generation/data/fragmented_network.gml"), format = "gml")

# calculate centrality
fragmented_centrality_local <- fragmented_network %>% 
  as_tbl_graph() %>% 
  mutate(degree = centrality_degree(),
         mean_degree = median(degree),
         is_low_degree = degree < mean_degree) %>% 
  select(who = id, degree, is_low_degree) %>% 
  as_tibble()

fragmented_centrality_local %>% 
  copy_to(sc, ., name = "fragmented_centrality", overwrite = TRUE)

fragmented_centrality <- tbl(sc, "fragmented_centrality")

fragmented_centrality
```

```{r}
degree_stats <- funding_status %>% 
  left_join(fragmented_centrality, by = "who") %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(cor_degree_sharing = cor(as.numeric(degree), as.numeric(shared_data)),
            cor_degree_funding = cor(as.numeric(degree), as.numeric(funded))) %>% 
  collect()
```

```{r}
degree_stats %>% 
  ggplot(aes(fundedshare, cor_degree_sharing, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point()
```

Correlations are negative, but not very strong. The negative correlation means
that teams with a lower degree share more. This is apparently the case. The
correlation is weak, since not all low-degree teams share data, simply because
not all teams are being funded. Once more teams are being funded, of course also
higher-degree teams are being funded, because there are only so few low-degree
teams.

How can we show this better? We can compute what the fraction of funded teams
which are low-degree is.

```{r}
# compute the share of teams being funded that are low-degree
low_degree_hypothesis <- funding_status %>% 
  left_join(fragmented_centrality, by = "who") %>% 
  group_by(maxinitialutility, fundedshare, run_number, step, funded) %>% 
  count(is_low_degree) %>% 
  mutate(fraction = n / sum(n)) %>% 
  filter(funded, is_low_degree) %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(mean_frac_low_degree_funded = mean(fraction)) %>% 
  collect()
```

```{r}
#| label: fig-low-degree-frac
#| fig-cap: "Representation of low-degree teams among funded teams. The dashed line indicates the share of teams with low degree in the sample. Values above the dashed line thus signal an over-representation of low-degree teams."
# what is the actual fraction of low degree teams?
true_fraction <- fragmented_centrality_local %>% 
  count(is_low_degree) %>% 
  mutate(n = n / 100) %>% 
  filter(is_low_degree) %>% 
  pull(n)

low_degree_hypothesis %>% 
  ggplot(aes(fundedshare, mean_frac_low_degree_funded, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = true_fraction, linetype = 2) +
  scale_y_continuous(breaks = c(true_fraction, seq(.4, to = .55, by = .05)))
```

We see that for high selectivity (funded share is low), low-degree teams are
over-represented among the funded teams. The analytic approach mirrors that of a
Chisquare test.

*The same with sharing*
```{r}
# compute the share of teams sharing data that are low-degree
low_degree_hypothesis_sharing <- funding_status %>% 
  left_join(fragmented_centrality, by = "who") %>% 
  group_by(maxinitialutility, fundedshare, run_number, step, shared_data) %>% 
  count(is_low_degree) %>% 
  mutate(fraction = n / sum(n)) %>% 
  filter(shared_data, is_low_degree) %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(mean_frac_low_degree_sharing = mean(fraction)) %>% 
  collect()
```

```{r}
#| label: fig-low-degree-frac-sharing
#| fig-cap: "Representation of low-degree teams among teams sharing data. The dashed line indicates the share of teams with low degree in the sample. Values above the dashed line thus signal an over-representation of low-degree teams."
low_degree_hypothesis_sharing %>% 
  ggplot(aes(fundedshare, mean_frac_low_degree_sharing, 
             colour = as.factor(maxinitialutility))) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = true_fraction, linetype = 2) +
  scale_y_continuous(breaks = c(true_fraction, seq(.4, to = .55, by = .05)))
```

```{r, eval=FALSE}
# THE CODE BELOW DOES NOT WORK CURRENTLY
# we cannot do a grouped chisquare in spark directly, therefore using spark_apply
test_fun <- function(df) {
  res <- chisq.test(df$funded, df$is_low_degree)
  broom::tidy(res)
}

chisquare_res <- funding_status %>% 
  # head(1000) %>%
  left_join(fragmented_centrality, by = "who") %>% 
  spark_apply(test_fun, 
              columns = c("maxinitialutility", "fundedshare", "run_number", 
                          "step")) %>% 
  group_by(maxinitialutility, fundedshare) %>% 
  summarise(mean_statistic = mean(statistic),
            mean_p = mean(p.value)) %>% 
  collect()

# We could also run it like this, but it does not do grouped tests, only executes on everything
#   group_by(maxinitialutility, fundedshare, run_number, step) %>% 
#   mutate(is_low_degree = as.character(is_low_degree),
#          funded = as.character(funded)) %>% 
#   ml_chisquare_test(features = "is_low_degree", label = "funded")
```

```{r}
spark_disconnect(sc)
```
